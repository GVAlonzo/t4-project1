{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48db7e1f",
   "metadata": {},
   "source": [
    "TO-DOs:\n",
    "\n",
    "INCIDENT FILE\n",
    "- COMPLETED: Parse-out the time from the date/time columns  (Converted to datetime)\n",
    "- COMPLETED: Calculate the arrival times\n",
    "- COMPLETED: Create FINAL dataframe for our assignments\n",
    "\n",
    "STATION FILE\n",
    "- COMPLETED: Only contain CLV stations\n",
    "\n",
    "\n",
    "ASSIGNMENTS:\n",
    "- IN PROGRESS: Google map the CLV station on a map?  (Margot)\n",
    "- IN PROGRESS: Add clicable names to the pins?  (Margot)\n",
    "- IN PROGRESS: Pie chart for incident type (Saeger)\n",
    "- IN PROGRESS: Bar chart by incident for each station (Saeger)\n",
    "- IN PROGRESS: Bar chart by response time for each station (Saeger)\n",
    "- ASSIGNED: Hypothesis Testing (Anji)\n",
    "        - Boxplots?\n",
    "        - Determine Mean vs Median based on number of outliers?\n",
    "- ASSIGNED: Trends - number of incidents by month compared to previous years (George)\n",
    "- ASSIGNED: Trends - Avg response time by month compared to previous years (George)\n",
    "- TBD: Pick the highest performing station (lowest avg response times) vs least performing station (highest avg response times)  and look into why  (Further charting for each?)\n",
    "- TBD: Quality control & code clean-up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9153d8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPENDENCIES\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Declare variables for each CSV file\n",
    "incident_file_df1114 = \"data/Fire_Department_Incident_Count - 2011-2014.csv\"\n",
    "incident_file_df1516 = \"data/Fire_Department_Incident_Count - 2015-2016.csv\"\n",
    "incident_file_df1718 = \"data/Fire_Department_Incident_Count - 2017-2018.csv\"\n",
    "fire_station_data =  \"data/Clark_County_Fire_Stations.csv\"\n",
    "\n",
    "#import gmaps\n",
    "import gmaps\n",
    "\n",
    "# Import API key\n",
    "from configure import g_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49bebbb",
   "metadata": {},
   "source": [
    "PROCESS INCIDENT DATA HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8169c399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: bring-in 2011-2014 data into a df\n",
    "\n",
    "incident_file_df1718 = pd.read_csv(incident_file_df1718)\n",
    "print(f\"# of rows in 2017-2018 DF: {len(incident_file_df1718)}\")\n",
    "\n",
    "incident_file_df1516 = pd.read_csv(incident_file_df1516)\n",
    "print(f\"# of rows in 2014-2015 DF: {len(incident_file_df1516)}\")\n",
    "\n",
    "incident_file_df1114 = pd.read_csv(incident_file_df1114)\n",
    "print(f\"# of rows in 2011-2014 DF: {len(incident_file_df1114)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d219d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatonate previous DFs into a single dataframe\n",
    "\n",
    "incident_file_df = pd.concat([incident_file_df1114, incident_file_df1516, incident_file_df1718])\n",
    "incident_file_df = incident_file_df.dropna(how='any')\n",
    "print(f\"# of rows in complete file: {len(incident_file_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126c2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New DF with only the required columns and ignore the others\n",
    "\n",
    "incident_file_lean_df = incident_file_df[[\"Station\",\"Response_Date\",\"Event_Type\",\"First_Unit_Assigned\",\"First_Unit_Arrived\",\"Location\",\"Location_1\"]]\n",
    "incident_file_lean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32864b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new df for rows that DO NOT contain 'none' in the First_Unit_Arrived column\n",
    "incident_file_clean_df = incident_file_lean_df[incident_file_lean_df[\"First_Unit_Arrived\"] != \"None\"]\n",
    "\n",
    "#incident_file_clean_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eaf6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Assigned & Arrived times to DateTime, remove timezones\n",
    "incident_file_clean_df[\"First_Unit_Assigned\"] = pd.to_datetime(incident_file_clean_df[\"First_Unit_Assigned\"])\n",
    "incident_file_clean_df[\"First_Unit_Arrived\"] = pd.to_datetime(incident_file_clean_df[\"First_Unit_Arrived\"])\n",
    "incident_file_clean_df[\"First_Unit_Assigned\"] = incident_file_clean_df[\"First_Unit_Assigned\"].dt.tz_localize(None)\n",
    "#incident_file_clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc1d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Response Time column\n",
    "incident_file_clean_df[\"Response Time\"] = (incident_file_clean_df[\"First_Unit_Arrived\"] - incident_file_clean_df[\"First_Unit_Assigned\"])\n",
    "incident_file_clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cfe437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform analysis\n",
    "#incident_file_clean_df.sort_values(\"Response Time\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f55c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create FINAL, cleaned dataframe, ready for analysis, charts, maps, and hypothesis testing!!!\n",
    "incident_file_final_df = incident_file_clean_df[incident_file_clean_df[\"First_Unit_Arrived\"] > \n",
    "                                                incident_file_clean_df[\"First_Unit_Assigned\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73e1488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#incident_file_final_df.count()\n",
    "#incident_file_final_df.sort_values(\"Response Time\",ascending=False)\n",
    "#incident_file_final_df.max()\n",
    "#incident_file_final_df.max()\n",
    "#incident_file_final_df.count()\n",
    "incident_file_final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe0914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c939907",
   "metadata": {},
   "source": [
    "PROCESS FIRE STATION DATA (MARGOT'S SECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring-in fire station data\n",
    "station_df = pd.read_csv(fire_station_data)\n",
    "print(f\"# of rows in the Station data file: {len(station_df)}\")\n",
    "#station_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebb1a27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distinct_stations = incident_file_clean_df[\"Station\"].unique()\n",
    "clv_stations_df = station_df[station_df[\"CITY_CODE\"] == \"CLV\"]\n",
    "clv_stations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ee456b",
   "metadata": {},
   "source": [
    "INCIDENT TYPES & COUNTS (SAEGER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85b80b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1b474d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85099433",
   "metadata": {},
   "source": [
    "RESPONSE TIMES ANALYSIS (GEORGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d1e47b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade92d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97b7c6ca",
   "metadata": {},
   "source": [
    "HYPOTHESIS TESTING (ANJI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44983b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e81302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access maps with unique API key\n",
    "gmaps.configure(api_key=g_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40ff09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a map of Firehouse locations\n",
    "station_locations = clv_stations_df[['LAT','LONG']]\n",
    "\n",
    "fig = gmaps.figure()\n",
    "markers = gmaps.marker_layer(station_locations)\n",
    "\n",
    "\n",
    "\n",
    "# # Using the template add the hotel marks to the heatmap\n",
    "# info_box_template = \"\"\"\n",
    "# <dl>\n",
    "# <dt>Name</dt><dd>{Hotel Name}</dd>\n",
    "# <dt>City</dt><dd>{City}</dd>\n",
    "# <dt>Country</dt><dd>{Country}</dd>\n",
    "# </dl>\n",
    "# \"\"\"\n",
    "# # Store the DataFrame Row\n",
    "# # NOTE: be sure to update with your DataFrame name\n",
    "# hotel_info = [info_box_template.format(**row) for index, row in hotel_df.iterrows()]\n",
    "   \n",
    "fig.add_layer(markers)\n",
    "fig\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
